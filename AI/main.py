import os
import boto3
import tempfile
import mimetypes
from dotenv import load_dotenv
import numpy as np
import pdfplumber
import pytesseract
from PIL import Image
from docx import Document
from sentence_transformers import SentenceTransformer
import pinecone
import uuid
from urllib.parse import urlparse
from pptx import Presentation
import zipfile



load_dotenv()  # ×˜×•×¢×Ÿ ××ª ××©×ª× ×™ ×”×¡×‘×™×‘×” ××”×§×•×‘×¥ .env

openai_api_key = os.getenv("OPENAI_API_KEY")
pinecone_api_key = os.getenv("PINECONE_API_KEY")

from urllib.parse import unquote
import openai
from pinecone import Pinecone, ServerlessSpec
openai.api_key = openai_api_key
# Initialize Pinecone instance
pinecone = Pinecone(
    api_key=pinecone_api_key,
    ssl_verify=False
)
spec = ServerlessSpec(
    cloud="aws",
    region="us-east-1"
)
pinecone_index_name = "user-files"

# ××•×“×œ ×œ×××‘×“×™× ×’
# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
embedding_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')
# ×”×•×¨×“×ª ×§×•×‘×¥ ×-S3
import requests
aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID")
aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY")

def create_presigned_url(bucket_name, object_key, expiration=3600):
    s3_client = boto3.client(
        's3',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        )
    try:
        response = s3_client.generate_presigned_url('get_object',
                                                    Params={'Bucket': bucket_name, 'Key': object_key},
                                                    ExpiresIn=expiration)
    except Exception as e:
        print(f"â— Error generating presigned URL: {e}")
        raise
    return response


def download_s3_file(s3_url):
    print(f"ğŸ“¥ Downloading from URL: {s3_url}")
    try:
        response = requests.get(s3_url, stream=True)
        response.raise_for_status()
        content_type = response.headers.get('Content-Type', '')
        extension = mimetypes.guess_extension(content_type) or ''
        file_name = "unknown_file"

        if not extension:
            parsed_url = urlparse(s3_url)
            file_name = os.path.basename(parsed_url.path)
            extension = os.path.splitext(file_name)[1]  # ×§×‘×œ×ª ×”×¡×™×•××ª ××”×©×
        print(f"ğŸ“„ ×©× ×”×§×•×‘×¥ ××”-URL: {file_name}")
        print(f"ğŸ“„ ×¡×™×•××ª ×”×§×•×‘×¥: {extension}")
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=extension)

        with open(temp_file.name, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        print(f"ğŸ“‚ ×§×•×‘×¥ ×–×× ×™ × ×©××¨ ×‘× ×ª×™×‘: {temp_file.name}")
        return temp_file.name
    except Exception as e:
        print(f"â— Error downloading file: {e}")
        raise

from PIL import Image

def validate_and_convert_image(file_path):
    """
    ×”××¨×ª ×ª××•× ×” ×œ×¤×•×¨××˜ PNG ×× × ×“×¨×©
    """
    try:
        img = Image.open(file_path)
        converted_path = file_path + ".png"
        img.save(converted_path, format="PNG")
        return converted_path
    except Exception as e:
        print(f"â— ×©×’×™××” ×‘×”××¨×ª ×”×ª××•× ×”: {e}")
        return None


def extract_text(file_path):
    ext = os.path.splitext(file_path)[1].lower().replace('.', '')  # ×ª××™×“ × ×©×ª××© ×‘×¡×™×•××ª ×›××• 'txt'
    print(f"ğŸ“‚ × ×ª×™×‘ ×”×§×•×‘×¥: {file_path}")
    print(f"ğŸ“„ ×¡×™×•××ª ×”×§×•×‘×¥: {ext}")
    text = ""

    try:
        if ext in ['txt', 'md', 'json', 'csv', 'py', 'js', 'html', 'css']:
            # ×§×¨×™××ª ×§×‘×¦×™ ×˜×§×¡×˜
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()

        elif ext == 'pdf':
            # ×§×¨×™××ª ×§×‘×¦×™ PDF
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() or ""

        elif ext == 'docx':
            # ×§×¨×™××ª ×§×‘×¦×™ Word
            doc = Document(file_path)
            for para in doc.paragraphs:
                text += para.text + "\n"

        elif ext in ['jpeg', 'jpg', 'png']:
             mime_type = f"image/{ext if ext != 'jpg' else 'jpeg'}"
             text = transcribe_image_with_ai(file_path, mime_type)
        elif ext in ['mp4', 'mov', 'avi', 'mkv']:
            # ×ª××œ×•×œ ×•×™×“××• ×‘×××¦×¢×•×ª AI
            text = transcribe_video_with_ai(file_path)
        elif ext == 'zip':
            text = extract_text_from_zip(file_path)
        elif ext == 'pptx':
            text = extract_text_from_pptx(file_path)
        elif ext in ['mp3', 'wav', 'ogg']:
            text = transcribe_audio_with_ai(file_path)
        else:
            print(f"âš ï¸ ×¡×™×•××ª ×œ× × ×ª××›×ª: {ext}")
            text = "×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š ×œ×§×¨×™××” ×™×©×™×¨×”."
    except Exception as e:
        print(f"â— ×©×’×™××” ×‘×§×¨×™××ª ×”×§×•×‘×¥: {e}")
        text = ""

    return text

import base64

def extract_text_from_zip(file_path):
    """
    ×—×™×œ×•×¥ ×˜×§×¡×˜ ××›×œ ×”×§×‘×¦×™× ×”×–××™× ×™× ×‘-ZIP (×ª×•×š ×”×ª×¢×œ××•×ª ××§×‘×¦×™× ×‘×™× ××¨×™×™×)
    """
    text = ""
    try:
        with zipfile.ZipFile(file_path, 'r') as zip_ref:
            for file_info in zip_ref.infolist():
                if not file_info.filename.endswith(('.jpg', '.png', '.mp4', '.mov', '.avi', '.mp3', '.wav')):
                    with zip_ref.open(file_info.filename) as file:
                        try:
                            content = file.read().decode('utf-8', errors='ignore')
                            text += f"\n\n--- {file_info.filename} ---\n\n{content}"
                        except Exception as e:
                            print(f"×©×’×™××” ×‘×§×¨×™××ª {file_info.filename}: {e}")
    except Exception as e:
        print(f"×©×’×™××” ×‘×¤×¢× ×•×— ×§×•×‘×¥ ZIP: {e}")
    return text



def extract_text_from_pptx(file_path):
    """
    ×©×œ×™×¤×ª ×˜×§×¡×˜ ×××¦×’×ª PowerPoint
    """
    text = ""
    try:
        prs = Presentation(file_path)
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"
    except Exception as e:
        print(f"×©×’×™××” ×‘×§×¨×™××ª PPTX: {e}")
    return text

def transcribe_audio_with_ai(file_path):
    """
    ×ª××œ×•×œ ×§×•×‘×¥ ××•×“×™×• ×‘×××¦×¢×•×ª Whisper
    """
    try:
        with open(file_path, "rb") as audio_file:
            transcript = openai.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        return transcript.text
    except Exception as e:
        print(f"×©×’×™××” ×‘×ª××œ×•×œ ×”××•×“×™×•: {e}")
        return f"×©×’×™××” ×‘×ª××œ×•×œ ×”××•×“×™×•: {str(e)}"


def transcribe_image_with_ai(file_path,mime_type):
    """
    ×©×œ×™×—×ª ×ª××•× ×” ×œ-OpenAI ×¢× ×¤×¨×•××¤×˜ ××•×ª×× ×œ×§×‘×œ×ª ×ª×™××•×¨ ×©×œ ×”×ª××•× ×”
    """
    print(f"ğŸ“¤ ×©×œ×™×—×ª ×ª××•× ×” ×œ-OpenAI ×œ×ª×™××•×¨: {file_path}")
    try:
        with open(file_path, "rb") as img_file:
            b64 = base64.b64encode(img_file.read()).decode("utf-8")
        data_url = f"data:{mime_type};base64,{b64}"

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": [
                    {"type": "text", "text": " ×ª××¨ ×œ×™ ××ª ××” ×©×¨×•××™× ×‘×ª××•× ×” ×”×–×• ×›×•×œ×œ ××™×œ×™× ×©×¨×©×•××•×ª ×‘×”, ×¦×‘×¢×™×, ×¤×¨×˜×™× ×•×›×•'."},
                    {"type": "image_url", "image_url": {"url": data_url}},
                ]}
            ]
        )
        return response.choices[0].message.content

    except Exception as e:
        print(f"â— ×©×’×™××” ×‘×©×œ×™×—×ª ×”×ª××•× ×” ×œ-OpenAI: {e}")
        return f"â— ×©×’×™××” ×‘× ×™×ª×•×— ×”×ª××•× ×” ×¢× OpenAI: {str(e)}"
   
def transcribe_video_with_ai(file_path):
    """
    ×ª××œ×•×œ ×•×™×“××• ×œ×§×•×‘×¥ ×˜×§×¡×˜ ×‘×¢×–×¨×ª OpenAI Whisper
    """
    print(f"ğŸ“¤ ×©×œ×™×—×ª ×ª××•× ×” ×œ-OpenAI ×œ×ª×™××•×¨: {file_path}")
    try:
        with open(file_path, "rb") as video_file:
            transcript = openai.audio.transcriptions.create(
                model="whisper-1",
                file=video_file
            )
        return transcript.text

    except Exception as e:
        print(f"â— ×©×’×™××” ×‘×ª××œ×•×œ ×”×•×™×“××•: {e}")
        return f"â— ×©×’×™××” ×‘×ª××œ×•×œ ×”×•×™×“××•: {str(e)}"

  
# ×¤×™×¦×•×œ ×˜×§×¡×˜ ×œ×¤×¡×§××•×ª ×§×˜× ×•×ª
def split_text(text, max_chunk_size=500):
    paragraphs = text.split("\n\n")
    chunks = []
    current_chunk = ""

    for para in paragraphs:
        if len(current_chunk) + len(para) <= max_chunk_size:
            current_chunk += para + "\n\n"
        else:
            chunks.append(current_chunk.strip())
            current_chunk = para + "\n\n"

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks

import uuid  # ×•×“× ×©×”××•×“×•×œ ××™×•×‘×

def index_s3_file_for_user(s3_url: str, content: str, file_id: str):
    # ×©×œ×‘ 1: ×”×•×¨×“×”
    if(s3_url!=""):  
        print(f"ğŸ“¥ ×”×•×¨×“×ª ×”×§×•×‘×¥ ×-S3: {s3_url}")
        try:
            parsed_url = urlparse(s3_url)
            netloc_parts = parsed_url.netloc.split('.')
            if len(netloc_parts) < 2:
                raise ValueError(f"Invalid S3 URL format: {s3_url}")
            
            bucket_name = netloc_parts[0]
            object_key = unquote(parsed_url.path.lstrip('/'))  # âœ… ×—×©×•×‘

            print("ğŸ“‚ object_key:", object_key)

            # ×™×¦×™×¨×ª Presigned URL
            presigned_url = create_presigned_url(bucket_name, object_key)

            # ×”×•×¨×“×ª ×”×§×•×‘×¥
            local_file_path = download_s3_file(presigned_url)
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘××”×œ×š ×”×•×¨×“×ª ×”×§×•×‘×¥: {e}")
            return

        # ×©×œ×‘ 2: ×§×¨×™××ª ×”×ª×•×›×Ÿ
        try:
            text = extract_text(local_file_path)
            if not text.strip():
                print(f"âš ï¸ ×”×§×•×‘×¥ ×¨×™×§ ××• ×œ× × ×ª××š: {s3_url}")
                os.remove(local_file_path)
                return
            text = f"{content}\n{text}"  # ×©×™×œ×•×‘ content ×¢× ×”×˜×§×¡×˜ ××”×§×•×‘×¥

        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘××”×œ×š ×§×¨×™××ª ×”×ª×•×›×Ÿ: {e}")
            os.remove(local_file_path)
            return
    else:
        # ×× ××™×Ÿ S3 URL, × ×©×ª××© ×‘×ª×•×›×Ÿ ×™×©×™×¨×•×ª
        text = content
        local_file_path = None
    # ×©×œ×‘ 3: ×—×œ×•×§×” ×œ×—×œ×§×™×
    text_chunks = split_text(text)

    # ×©×œ×‘ 4: ×™×¦×™×¨×ª ×××‘×“×™× ×’×™×
    try:
        embeddings = embedding_model.encode(text_chunks)
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘××”×œ×š ×™×¦×™×¨×ª ×××‘×“×™× ×’×™×: {e}")
        os.remove(local_file_path)
        return

    # ×©×œ×‘ 5: ×©×œ×™×—×” ×œ-Pinecone
    try:
        if pinecone_index_name not in pinecone.list_indexes().names():
            pinecone.create_index(
                name=pinecone_index_name,
                dimension=len(embeddings[0]),
                metric="cosine",
                spec=spec
            )

        index = pinecone.Index(pinecone_index_name)

        vectors = []
        for idx, (chunk, embedding) in enumerate(zip(text_chunks, embeddings)):
            vectors.append({
                "id": f"{file_id}_{uuid.uuid4().hex}",
                "values": embedding.tolist(),
                "metadata": {
                    # "user_id": user_id,
                    "file_id": file_id,
                    "text": chunk
                }
            })

        index.upsert(vectors)

        # print(f"âœ”ï¸ {len(vectors)} ×§×˜×¢×™× ×”×•×›× ×¡×• ×œ-Pinecone ×ª×—×ª ××©×ª××© {user_id} ××”×§×•×‘×¥ {file_id}")
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘××”×œ×š ×©×œ×™×—×” ×œ-Pinecone: {e}")
    finally:
        # × ×™×§×•×™ ×§×•×‘×¥ ×–×× ×™
        os.remove(local_file_path)

def describe_file_from_url(file_url):
    # ×©×œ×‘ 1: ×”×•×¨×“×ª ×”×§×•×‘×¥
    response = requests.get(file_url)
    if response.status_code != 200:
        return "Failed to download the file."

    # ×©×œ×‘ 2: ×–×™×”×•×™ ×¡×•×’ MIME
    content_type = response.headers.get('Content-Type')
    ext = mimetypes.guess_extension(content_type)

    # ×©×œ×‘ 3: ×©××™×¨×” ×–×× ×™×ª
    with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as tmp_file:
        tmp_file.write(response.content)
        tmp_file_path = tmp_file.name

    # ×©×œ×‘ 4: ×”×›× ×” ×œ×©×œ×™×—×” ×œ-AI
    if 'image' in content_type:
        # ×ª××•× ×” - ×©×œ×™×—×” ×œ-GPT-4-Vision
        with open(tmp_file_path, "rb") as image_file:
            result = openai.ChatCompletion.create(
                model="gpt-4-vision-preview",
                messages=[
                    {"role": "user", "content": [
                        {"type": "text", "text": "Please describe the content of this image."},
                        {"type": "image_url", "image_url": {"url": f"data:{content_type};base64,{image_file.read().encode('base64')}"}}  # ×©×™××™ ×œ×‘ â€“ ×¨×§ ×× ×™×© ×ª××™×›×”
                    ]}
                ],
                max_tokens=300
            )
            return result.choices[0].message['content']

    elif 'pdf' in content_type or 'text' in content_type:
        # ×˜×§×¡×˜×™× â€“ ×§×¨×™××” ×•×©×œ×™×—×” ×œ-GPT
        text = response.content.decode(errors='ignore')[:2000]  # × ×™×§×— ×¨×§ ×ª×—×™×œ×ª ×”×§×•×‘×¥ ×›×“×™ ×œ× ×œ×¢×‘×•×¨ ××’×‘×œ×ª ×˜×•×§× ×™×
        result = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": f"Please describe the content of this file:\n{text}"}],
            max_tokens=300
        )
        return result.choices[0].message['content']

    elif 'audio' in content_type or 'video' in content_type:
        # ×©×œ×™×—×” ×œ-Whisper (×œ×“×•×’××”, ×¨×§ ××•×“×™×•)
        with open(tmp_file_path, "rb") as media_file:
            transcript = openai.Audio.transcribe("whisper-1", media_file)
            return f"Transcription of the file:\n{transcript['text']}"

    else:
        return "Unsupported file type for automatic description."
def get_embedding(text):
    text_chunks = split_text(text)
    embeddings = embedding_model.encode(text_chunks)   
    return embeddings
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"), ssl_verify=False)
index = pc.Index("user-files")

def query_user_files(query: str, score_threshold: float = 0.8, top_k: int = 10):
    """
    ×¤×•× ×§×¦×™×” ×œ×—×™×¤×•×© ×§×‘×¦×™× ×œ×¤×™ ×©××™×œ×ª×” ×‘×œ×‘×“, ×›×•×œ×œ × ×¨××•×œ ×¦×™×•× ×™× ×•××™×•×Ÿ ×ª×•×¦××•×ª
    """
    print(f"ğŸ” ×—×™×¤×•×© ×§×‘×¦×™× ×¢× ×©××™×œ×ª×”: {query}")
    try:
        # ×™×¦×™×¨×ª ×××‘×“×™× ×’ ×œ×©××™×œ×ª×”
        query_embedding = embedding_model.encode([query])[0]
        print(f"ğŸ¤” Query Embedding: {query_embedding}")

        # ×‘×“×™×§×ª ×§×™×•× ×”××™× ×“×§×¡
        if pinecone_index_name not in pinecone.list_indexes().names():
            raise ValueError(f"âš ï¸ ××™× ×“×§×¡ {pinecone_index_name} ×œ× ×§×™×™× ×‘-Pinecone.")

        # ×—×™×¤×•×© ×‘××™× ×“×§×¡
        index = pinecone.Index(pinecone_index_name)
        results = index.query(
            vector=query_embedding.tolist(),
            top_k=5,  # ×—×™×¤×•×© ×¨××©×•× ×™ ×¢× ××¡×¤×¨ ×’×“×•×œ ×©×œ ×ª×•×¦××•×ª
            include_metadata=True
        )
        print(f"âœ… Results: {results}")
        
        import numpy as np

        # ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ×©×œ ×ª×•×¦××•×ª ×¢× ×¦×™×•×Ÿ ×œ×¤×—×•×ª 0.15
        filtered_matches = [
            match for match in results["matches"] if match["score"] >= 0.15
        ]

        # ×× ××™×Ÿ ×ª×•×¦××•×ª, × ×—×–×™×¨ ×¨×©×™××” ×¨×™×§×”
        if not filtered_matches:
            normalized_results = []
        else:
            # ×©×œ×‘ 1: ×—×™×©×•×‘ ×¡×˜×™×™×ª ×ª×§×Ÿ
            scores = [match["score"] for match in filtered_matches]
            max_score = max(scores)
            std = np.std(scores)

            # ×©×œ×‘ 2: ×¡×™× ×•×Ÿ ×ª×•×¦××•×ª ×©× ××¦××•×ª ×‘×ª×•×š ×¡×˜×™×™×ª ×ª×§×Ÿ ××—×ª ××”×¦×™×•×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨
            normalized_results = [
                {
                    "file_id": str(match["metadata"]["file_id"]),
                    "score": match["score"],
                    "text": match["metadata"]["text"]
                }
                for match in filtered_matches
                if match["score"] >= max_score - std
            ]


        # ××™×•×Ÿ ×”×ª×•×¦××•×ª ×œ×¤×™ ×¦×™×•×Ÿ (××”×’×‘×•×” ×œ× ××•×š)
        sorted_results = sorted(normalized_results, key=lambda x: x["score"], reverse=True)

        # ×”×’×‘×œ×ª ××¡×¤×¨ ×”×ª×•×¦××•×ª ×œ-top_k
        limited_results = sorted_results[:top_k]

        # ×”×—×–×¨×ª ×¨×©×™××ª ×”-file_id ×‘×œ×‘×“
        return [result["file_id"] for result in limited_results]

    except Exception as e:
        print(f"â— ×©×’×™××” ×‘×—×™×¤×•×© ×§×‘×¦×™×: {e}")
        raise


from fastapi import FastAPI
from pydantic import BaseModel
from typing import List
import uvicorn


from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://livefeedback-client.onrender.com"],  # ×¨×©×™××ª ××§×•×¨×•×ª ××•×¨×©×™×
    allow_credentials=True,
    allow_methods=["*"],  # ××ª×™×¨ ××ª ×›×œ ×¡×•×’×™ ×”×‘×§×©×•×ª
    allow_headers=["*"],  # ××ª×™×¨ ××ª ×›×œ ×¡×•×’×™ ×”×›×•×ª×¨×•×ª
)
# ---- ××•×“×œ×™× ×œ-Request ----

class IndexFileRequest(BaseModel):
    s3_url: str=""
    # user_id: int
    content: str =""
    file_id: int

class QueryFilesRequest(BaseModel):
    query: str
    score_threshold: float = 0.3 # ×¡×£ ×¦×™×•×Ÿ ×‘×¨×™×¨×ª ××—×“×œ
class QueryResult(BaseModel):
    file_id: int
    text_snippet: str
    score: float

# ---- ENDPOINTS ----

@app.post("/index-file")
def index_file(req: IndexFileRequest):
    print("ğŸ“‚ Indexing file request received.")
    try:
        print("req: ",req)
        index_s3_file_for_user(req.s3_url, req.content, req.file_id)
        return {"status": "success", "message": "File indexed successfully."}
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.post("/query-files", response_model=List[str])
def query_files(req: QueryFilesRequest):
    try:
        file_ids = query_user_files(req.query, req.score_threshold)
        return file_ids
    except Exception as e:
        return [f"Error: {str(e)}"]

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)

    